{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84c0486d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WSR cross results saved to: ./../../dataset/wsr_results_cross.csv\n",
      "Total rows: 728\n",
      "      Model Train_dataset Test_dataset BaseMetric ProposedMetric  \\\n",
      "0  adaboost          MEAN         MEAN   AUC_mean            AUC   \n",
      "1  adaboost           pc1          pc2   AUC_mean            AUC   \n",
      "2  adaboost           pc1          pc3   AUC_mean            AUC   \n",
      "3  adaboost           pc1          pc4   AUC_mean            AUC   \n",
      "4  adaboost           pc2          pc1   AUC_mean            AUC   \n",
      "\n",
      "   Baseline_mean  Proposed_mean  Difference  N_pairs  W_min_scipy  W_plus  \\\n",
      "0       0.766667       0.754418   -0.012249        5          0.0     0.0   \n",
      "1       0.794000       0.826308    0.032308        5          0.0    15.0   \n",
      "2       0.806000       0.802661   -0.003339        5          0.0     0.0   \n",
      "3       0.800000       0.771981   -0.028019        5          0.0     0.0   \n",
      "4       0.678000       0.680820    0.002820        5          0.0    15.0   \n",
      "\n",
      "   W_minus  W_signed  p_value  significant_0.05  significant_0.01  \\\n",
      "0     15.0     -15.0   0.0625             False             False   \n",
      "1      0.0      15.0   0.0625             False             False   \n",
      "2     15.0     -15.0   0.0625             False             False   \n",
      "3     15.0     -15.0   0.0625             False             False   \n",
      "4      0.0      15.0   0.0625             False             False   \n",
      "\n",
      "   effect_size_r  \n",
      "0           -1.0  \n",
      "1            1.0  \n",
      "2           -1.0  \n",
      "3           -1.0  \n",
      "4            1.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/uditjain/.pyenv/versions/3.11.11/lib/python3.11/site-packages/scipy/stats/_morestats.py:4088: UserWarning: Exact p-value calculation does not work if there are zeros. Switching to normal approximation.\n",
      "  warnings.warn(\"Exact p-value calculation does not work if there are \"\n",
      "/Users/uditjain/.pyenv/versions/3.11.11/lib/python3.11/site-packages/scipy/stats/_morestats.py:4102: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n",
      "/Users/uditjain/.pyenv/versions/3.11.11/lib/python3.11/site-packages/scipy/stats/_morestats.py:4088: UserWarning: Exact p-value calculation does not work if there are zeros. Switching to normal approximation.\n",
      "  warnings.warn(\"Exact p-value calculation does not work if there are \"\n",
      "/Users/uditjain/.pyenv/versions/3.11.11/lib/python3.11/site-packages/scipy/stats/_morestats.py:4102: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import wilcoxon, rankdata\n",
    "\n",
    "# ==== INPUT FILE PATHS ====\n",
    "baseline_file = \"./../../dataset/cross_baseline_5fold_values.csv\"\n",
    "proposed_file = \"./../../dataset/cross_proposed_5fold_values.csv\"\n",
    "\n",
    "# ==== READ DATA ====\n",
    "baseline = pd.read_csv(baseline_file).assign(\n",
    "    Train_norm=lambda df: df[\"Train\"].astype(str).str.replace(\".arff\", \"\", regex=False),\n",
    "    Test_norm=lambda df: df[\"Test\"].astype(str).str.replace(\".arff\", \"\", regex=False),\n",
    ")\n",
    "proposed = pd.read_csv(proposed_file).assign(\n",
    "    Train_norm=lambda df: df[\"Train\"].astype(str).str.replace(\".arff\", \"\", regex=False),\n",
    "    Test_norm=lambda df: df[\"Test\"].astype(str).str.replace(\".arff\", \"\", regex=False),\n",
    ")\n",
    "\n",
    "metric_map = {\n",
    "    \"AUC_mean\": \"AUC\",\n",
    "    \"F1_mean\": \"F1\",\n",
    "    \"Precision_mean\": \"Precision\",\n",
    "    \"Recall_mean\": \"Recall\",\n",
    "    \"Generalizability_mean\": \"GLR\",\n",
    "    \"Stability\": \"ECE\",\n",
    "    \"ReliabilityIndex\": \"ReliabilityScore\",\n",
    "}\n",
    "\n",
    "models = sorted(set(baseline[\"Model\"]) & set(proposed[\"Model\"]))\n",
    "results = []\n",
    "\n",
    "for model in models:\n",
    "    base_model = baseline[baseline[\"Model\"] == model]\n",
    "    prop_model = proposed[proposed[\"Model\"] == model]\n",
    "\n",
    "    for base_metric, prop_metric in metric_map.items():\n",
    "        base_rows = base_model[base_model[\"Metric\"] == base_metric]\n",
    "        prop_rows = prop_model[prop_model[\"Metric\"] == prop_metric]\n",
    "\n",
    "        if base_rows.empty or prop_rows.empty:\n",
    "            continue\n",
    "\n",
    "        merged = base_rows.merge(\n",
    "            prop_rows,\n",
    "            on=[\"Train_norm\", \"Test_norm\", \"Fold\"],\n",
    "            suffixes=(\"_baseline\", \"_proposed\"),\n",
    "        )\n",
    "\n",
    "        if merged.empty:\n",
    "            continue\n",
    "\n",
    "        for (train, test), subset in merged.groupby([\"Train_norm\", \"Test_norm\"]):\n",
    "            b_vals = subset[\"Value_baseline\"].to_numpy()\n",
    "            p_vals = subset[\"Value_proposed\"].to_numpy()\n",
    "\n",
    "            if b_vals.size == 0 or p_vals.size == 0:\n",
    "                continue\n",
    "            if b_vals.shape != p_vals.shape:\n",
    "                continue\n",
    "\n",
    "            diffs = p_vals - b_vals\n",
    "            n_pairs = len(diffs)\n",
    "            baseline_mean = float(b_vals.mean())\n",
    "            proposed_mean = float(p_vals.mean())\n",
    "            difference = float(proposed_mean - baseline_mean)\n",
    "\n",
    "            if np.allclose(diffs, 0, equal_nan=True):\n",
    "                W_min_scipy = np.nan\n",
    "                W_plus = 0.0\n",
    "                W_minus = 0.0\n",
    "                W_signed = 0.0\n",
    "                pval = np.nan\n",
    "                effect_r = 0.0\n",
    "            else:\n",
    "                nz_mask = diffs != 0\n",
    "                d = diffs[nz_mask]\n",
    "\n",
    "                if d.size == 0:\n",
    "                    W_min_scipy = np.nan\n",
    "                    W_plus = 0.0\n",
    "                    W_minus = 0.0\n",
    "                    W_signed = 0.0\n",
    "                    pval = np.nan\n",
    "                    effect_r = 0.0\n",
    "                else:\n",
    "                    ranks = rankdata(np.abs(d))\n",
    "                    W_plus = ranks[d > 0].sum()\n",
    "                    W_minus = ranks[d < 0].sum()\n",
    "                    W_signed = W_plus - W_minus\n",
    "\n",
    "                    try:\n",
    "                        w_res = wilcoxon(\n",
    "                            p_vals,\n",
    "                            b_vals,\n",
    "                            alternative=\"two-sided\",\n",
    "                            zero_method=\"wilcox\",\n",
    "                            mode=\"auto\",\n",
    "                        )\n",
    "                        W_min_scipy = float(w_res.statistic)\n",
    "                        pval = float(w_res.pvalue)\n",
    "                    except ValueError:\n",
    "                        W_min_scipy = np.nan\n",
    "                        pval = np.nan\n",
    "\n",
    "                    denom = W_plus + W_minus\n",
    "                    effect_r = (W_signed / denom) if denom != 0 else np.nan\n",
    "\n",
    "            results.append(\n",
    "                {\n",
    "                    \"Model\": model,\n",
    "                    \"Train_dataset\": train,\n",
    "                    \"Test_dataset\": test,\n",
    "                    \"BaseMetric\": base_metric,\n",
    "                    \"ProposedMetric\": prop_metric,\n",
    "                    \"Baseline_mean\": baseline_mean,\n",
    "                    \"Proposed_mean\": proposed_mean,\n",
    "                    \"Difference\": difference,\n",
    "                    \"N_pairs\": n_pairs,\n",
    "                    \"W_min_scipy\": W_min_scipy,\n",
    "                    \"W_plus\": W_plus,\n",
    "                    \"W_minus\": W_minus,\n",
    "                    \"W_signed\": W_signed,\n",
    "                    \"p_value\": pval,\n",
    "                    \"significant_0.05\": bool(\n",
    "                        pval is not None and not np.isnan(pval) and pval <= 0.05\n",
    "                    ),\n",
    "                    \"significant_0.01\": bool(\n",
    "                        pval is not None and not np.isnan(pval) and pval <= 0.01\n",
    "                    ),\n",
    "                    \"effect_size_r\": effect_r,\n",
    "                }\n",
    "            )\n",
    "\n",
    "wsr_df = pd.DataFrame(results)\n",
    "\n",
    "output_file = \"./../../dataset/wsr_results_cross.csv\"\n",
    "wsr_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"WSR cross results saved to: {output_file}\")\n",
    "print(f\"Total rows: {len(wsr_df)}\")\n",
    "print(wsr_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab11b8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
